# Phase 3: LLM-Powered Copy Editor Implementation Plan

**Objective:** To integrate an LLM-powered copy editing feature into Vibe Write, focusing initially on grammar, conciseness, and basic style, with a provision for client-side spell checking. This plan emphasizes a granular, step-by-step approach to manage complexity and ensure robust implementation, particularly around LLM interaction and text manipulation.

**Core LLM:** `gemma3:4b` (via local Ollama instance)

**Guiding Principles & Key Strategies for LLM Interaction:**

*   **Ultra-Specific Prompts:** Instruct the LLM precisely on its task, the desired output format (e.g., JSON), and what *not* to do (e.g., be conversational, rewrite entire sections unless asked).
*   **Analyze Smallest Sensible Chunks:** Process text in manageable units (e.g., paragraphs) to limit the "blast radius" of potential LLM inaccuracies and to make suggestions more targeted.
*   **User-Initiated "Accept":** All LLM suggestions must be reviewed and explicitly accepted by the user. No automatic application of changes.
*   **Use Diffing for Display:** Use text diffing algorithms to *display* inline changes between the original and suggested paragraph.
*   **Iterative Prompt Refinement:** Continuously test and refine prompts based on LLM output to improve accuracy and reliability.
*   **Temperature Setting:** Utilize lower temperature settings (e.g., `0.2` or lower) for Ollama calls to encourage more deterministic and less "creative" responses suitable for editing tasks.

---

## Section 1: Foundation (Common for all LLM-based editing features)

**Status: COMPLETED**

This section covers the initial setup of UI elements and IPC communication required for all subsequent LLM-driven copy editing features.

### F3.0: Basic UI for Copy Editing Trigger & Display **(COMPLETED)**

*   **F3.0.1 (UI - Renderer `index.html`):** (COMPLETED)
    *   Add an "Analyze for Issues" button (or similar).
*   **F3.0.2 (UI - Renderer `index.html`):** (COMPLETED)
    *   Create a dedicated area (e.g., a sidebar, a collapsible panel below the editor, or a modal) to list suggestions.
    *   Initially, this area will display raw text suggestions, not in-editor highlights.
*   **Test Criteria (F3.0.1 & F3.0.2):** (MET)

*   **F3.0.3 (IPC - `preload.js` & `main.js`):** (COMPLETED)
    *   Define a new IPC channel in `preload.js`:
        ```javascript
        window.api.invokeCopyAnalysis = (text, analysisType) => ipcRenderer.invoke('invoke-copy-analysis', { text, analysisType });
        ```
*   **F3.0.4 (IPC - `main.js`):** (COMPLETED)
    *   Create a basic handler in `main.js` for `invoke-copy-analysis`:
        ```javascript
        ipcMain.handle('invoke-copy-analysis', async (event, { text, analysisType }) => {
          console.log(`Received text for analysisType '${analysisType}':`, text.substring(0, 100) + "..."); // Log first 100 chars
          // TODO: Implement actual analysis logic
          return { success: true, message: "Analysis request received (mock response)." };
        });
        ```
*   **Test Criteria (F3.0.3 & F3.0.4):** (MET)
    *   Clicking the "Analyze for Issues" button (once connected in `script.js`) triggers the `invoke-copy-analysis` handler in `main.js`.
    *   The `main.js` console logs the received text and `analysisType`.
    *   The renderer process receives the mock success message.

---

## Section 2: Iteration 1 - LLM Grammar Check (Paragraph Rewrite + Inline Diff Display)

**Status: COMPLETED (Strategy Evolved)**

**Note:** The initial strategy evolved significantly. Attempts at granular suggestions faced cascading update issues. The final approach uses an LLM-based paragraph rewrite, calculates the diff between original and corrected, and displays this diff inline within the suggestion panel. Applying the suggestion replaces the entire paragraph.

This iteration focuses on implementing grammar checking using the LLM, displaying suggestions with inline diffs, and allowing users to apply them at the paragraph level.

### F3.1: Paragraph-based Grammar Analysis & Diff Generation **(COMPLETED - Final Strategy)**

*   **F3.1.1 (Backend - `main.js`):** (COMPLETED)
    *   **Modify `invoke-copy-analysis` Handler:** Handles `analysisType="grammar"` (sole type currently).
    *   **Chunking Logic:** Splits text into paragraphs.
    *   **Prompt Engineering (Grammar - `gemma3:4b`):** Prompts LLM to rewrite the paragraph with corrections (plain text output).
    *   **LLM Interaction:** Loops paragraphs, sends to Ollama, gets rewritten paragraph.
    *   **Suggestion Aggregation:** If rewritten paragraph differs from original, creates *one* suggestion object containing:
        *   `id`, `paragraphIndex`, `analysisType`
        *   `originalParagraph`: The full original paragraph text.
        *   `correctedParagraph`: The full LLM-corrected paragraph text.
        *   `changes`: The array generated by `diff.diffWordsWithSpace` comparing original and corrected.
*   **Test Criteria (F3.1.1):** (MET - for final strategy)
    *   `main.js` correctly processes paragraphs, calls LLM, and generates suggestion objects with original/corrected text and a diff array.

*   **F3.1.2 (Frontend - `script.js`):** (COMPLETED)
    *   **Trigger Analysis:** Calls `window.api.invokeCopyAnalysis(editorContent, "grammar")`.
    *   **Display Suggestions:** Renders the `changes` array from each suggestion object into HTML with `<ins>` and `<del>` tags (or styled spans) to show inline differences within the "Analysis Suggestions" area.
*   **Test Criteria (F3.1.2):** (MET)
    *   Clicking "Analyze for Issues" triggers the process.
    *   Suggestions are displayed showing the corrected paragraph with additions/deletions highlighted inline.

### F3.2: Applying Paragraph-Level Suggestion **(COMPLETED - Final Strategy)**

*   **F3.2.1 (UI - Renderer `script.js` / `index.html`):** (COMPLETED)
    *   Adds an "Apply Suggestion for Paragraph X" button to each suggestion.
*   **F3.2.2 (Logic - Renderer `script.js`):** (COMPLETED)
    *   Clicking "Accept" retrieves the full `correctedParagraph` text from the corresponding suggestion object (stored locally in `script.js` after analysis).
    *   Replaces the *entire* original paragraph (identified by `paragraphIndex`) in the editor with the `correctedParagraph`.
    *   Removes the applied suggestion item from the display list.
*   **Test Criteria (F3.2.2):** (MET)
    *   Clicking "Apply" correctly replaces the paragraph in the editor.
    *   The preview updates.
    *   The suggestion item is removed from the list.
*   **F3.2.3 (Refinement - N/A):** (REMOVED)
    *   Complex sub-phrase replacement logic is no longer needed with the paragraph-level atomic update approach.

---

## Section 3: Iteration 2 - Client-Side Spell Check Integration

**Status: REMOVED / OBSOLETE**

**Note:** This feature was removed as LLM-based grammar checking effectively handles most common spelling errors, and removing it simplifies the UI and workflow.

### F3.3: Basic JavaScript Spell Checker (REMOVED)

*   **F3.3.1 (Research & Integration - Renderer `script.js`):** (REMOVED)
*   **F3.3.2 (Display - Renderer `script.js` / `index.html` - Non-LLM):** (REMOVED)
*   **Test Criteria (F3.3.1 & F3.3.2):** (REMOVED)
*   **F3.3.3 (Suggestion & Correction - Renderer `script.js` - Non-LLM):** (REMOVED)
*   **Test Criteria (F3.3.3):** (REMOVED)

---

## Section 4: Iteration 3 - Conciseness (Paragraph by Paragraph, Suggestion List)

This iteration adds LLM-based analysis for conciseness, following a similar pattern to the grammar check.

### F3.4: LLM Conciseness Analysis

*   **(Follows pattern of F3.1)**
*   **F3.4.1 (Backend - `main.js`):**
    *   In the `invoke-copy-analysis` handler, if `analysisType` is `"conciseness"`:
    *   **Prompt Engineering (Conciseness - `gemma3:4b`):**
        *   For each paragraph, craft a prompt asking the LLM to:
            *   Identify filler words, redundant phrases, or wordy sentences.
            *   For each issue, provide the `originalPhrase`.
            *   Provide an `explanation` (e.g., "This phrase is wordy," "Filler word").
            *   Provide a `suggestedConcisePhrase`.
        *   Ensure the LLM returns this as a JSON array of objects (similar to grammar).
    *   Aggregate suggestions with `paragraphIndex`, unique `id`, `analysisType: "conciseness"`, etc.
*   **F3.4.2 (Frontend - `script.js`):**
    *   When "Analyze for Issues" is clicked (perhaps with a new option for analysis type, or analyze for all types), call `window.api.invokeCopyAnalysis(editorContent, "conciseness")`.
    *   Display conciseness suggestions in the dedicated list area, clearly marked or distinguished from grammar suggestions.
*   **Test Criteria (F3.4.1 & F3.4.2):**
    *   Send text with known wordiness or filler words.
    *   Verify `main.js` and LLM interaction for conciseness.
    *   Conciseness suggestions (with `originalPhrase`, `explanation`, `suggestedConcisePhrase`) populate the UI list.

### F3.5: Applying Conciseness Suggestions

*   **(Follows pattern of F3.2)**
*   **F3.5.1 (UI & Logic - Renderer `script.js`):**
    *   Add "Accept" buttons to conciseness suggestions.
    *   Implement replacement logic similar to F3.2.2, being mindful of potential LLM creativity. The strategies from F3.2.3 (constrained prompts, diffing) are equally important here.
*   **Test Criteria (F3.5.1):**
    *   Accepting conciseness suggestions correctly modifies the text in the editor.
    *   The text becomes more concise as intended.
    *   Live preview updates.

---

## Section 5: Subsequent Iterations & UI/UX Enhancements (Future Scope)

These are potential future steps once the foundational LLM-based editing and spell check are functional.

*   **F3.X: LLM Readability Analysis:**
    *   Similar pattern: Define `analysisType="readability"`.
    *   Prompt LLM to identify complex sentences, long sentences, or passages that are hard to read.
    *   LLM suggests simpler alternatives or ways to break down sentences.
    *   Implement display and "Accept" functionality.

*   **F3.Y: LLM Style Suggestions:**
    *   Examples: passive voice detection, clich√© identification.
    *   Each specific style suggestion might require its own focused prompt and `analysisType` (e.g., `"passivevoice"`, `"cliche"`).
    *   Implement display and "Accept" functionality.

*   **F3.Z: In-Editor Highlighting and Contextual Menus:**
    *   This is a significant UI/UX enhancement.
    *   **Goal:** Move away from a separate suggestion list to highlighting issues directly within the editor text.
    *   **Technical Exploration:**
        *   Investigate replacing the current `<textarea>` with a `contenteditable="true"> <div>`. This allows for wrapping text segments in `<span>` tags, which can then be styled (e.g., colored underlines) to indicate issues.
        *   Alternatively, explore integrating lightweight WYSIWYG or Markdown editor components that offer APIs for text marking and annotations (e.g., CodeMirror, TipTap, Milkdown). Evaluate their bundle size, complexity, and Markdown compatibility.
    *   **UX:**
        *   On hovering or clicking a highlighted section, display a small popup/tooltip showing the suggestion details (`explanation`, `correctedPhrase`) and an "Accept" button directly in context.

--- 